{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Channel measurements\n",
    "\n",
    "**Insight**\n",
    "* How does a real audio channel typically look like?\n",
    "* Is it well estimated using the deconvolution algorithm(s)?\n",
    "* Which transmit sequence should be used?\n",
    "* If we compare two channel estimates, can we estimate a difference in propagation time? And how does that translate into physical distance?\n",
    "\n",
    "These insights and results are very vital for this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Audio Beacon\n",
    "\n",
    "The audio beacon, once switched on, continuously transmits a sequence of pulses. It is controlled by a programmable microcontroller. It is possible to change the number of pulses, duration of each pulse, the sequence itself, and the period after which the sequence is repeated. The pulse sequence is a modulated binary code sequence with \"on-off keying\" (OOK). If a bit in the sequence is 0, nothing is transmitted; if the bit is 1, a modulation carrier frequency is transmitted during a certain period.\n",
    "\n",
    "Besides the actual bit sequence (code word), the parameters that determine the signal are:\n",
    "* Length of the code sequence (number of bits; parameter `NCodebits`), at most 64 bits;\n",
    "* Modulation carrier frequency (parameter `Timer0`), at most 30 kHz, although this is probably beyond the specs of the loudspeaker and microphones;\n",
    "* Duration of a single bit (parameter `Timer1`), this defines the rate at which the modulation carrier signal is switched on or off by the bits in the code word;\n",
    "* Repetition rate of the bit sequence (parameter `Timer3`). After the code sequence has been played over the loudspeaker, it will be silent for a certain period, and then the sequence is transmitted again, at a rate determined by Timer 3.\n",
    "\n",
    "To see what these different parameters mean, consider the image below:\n",
    "\n",
    "```{figure} Beacon.png\n",
    "---\n",
    "height/width: 150px\n",
    "name: beacon-figure\n",
    "---\n",
    "Beacon description\n",
    "```\n",
    "\n",
    "In the audio beacon in EPO4, these parameters can be modified by sending specific commands to the car, and this programs the microcontroller that generates the audio signal.\n",
    "\n",
    "The maximal repetition rate is 10 Hz (corresponding to a period of 100 ms). If 64 bits are used at the lowest rate of Timer 1 (1 kHz), then the duration of the sequence will be 64 ms. You will have to choose settings such that the channel impulse response dies out during the remaining period of silence, before the next pulse sequence starts.\n",
    "\n",
    "Possible values for the Timer parameters are listed in the table below; instead of the actual values, the Timer Index values are used. In the microcontroller, instead of setting the frequencies of the various timers directly, one would instead select the corresponding index (0 through 9).\n",
    "\n",
    "## Timer Frequencies\n",
    "\n",
    "| Timer Index           | 0     | 1      | 2      | 3      | 4      | 5      | 6      | 7      | 8      | 9      |\n",
    "|-----------------------|-------|--------|--------|--------|--------|--------|--------|--------|--------|--------|\n",
    "| Carrier Freq (Timer0) | 5 kHz | 10 kHz | 15 kHz | 20 kHz | 25 kHz | 30 kHz |        |        |        |        |\n",
    "| Code Freq (Timer1)    | 1.0 kHz | 1.5 kHz | 2.0 kHz | 2.5 kHz | 3.0 kHz | 3.5 kHz | 4.0 kHz | 4.5 kHz | 5.0 kHz |        |\n",
    "| Repeat Freq (Timer3)  | 1 Hz  | 2 Hz   | 3 Hz   | 4 Hz   | 5 Hz   | 6 Hz   | 7 Hz   | 8 Hz   | 9 Hz   | 10 Hz  |\n",
    "\n",
    "## Default Setting of the Audio Beacon\n",
    "\n",
    "The default setting of the audio beacon is a code sequence bit-stream of 32 bits with:\n",
    "\n",
    "| Setting             | Value  | Parameter           |\n",
    "|---------------------|--------|---------------------|\n",
    "| Code Length         | 32 bits | `NCODEBITS = 32`    |\n",
    "| Carrier Frequency   | 20 kHz | `TIMER0_INDEX = 3`  |\n",
    "| Code Frequency      | 5 kHz  | `TIMER1_INDEX = 8`  |\n",
    "| Repeat Frequency    | 2 Hz   | `TIMER3_INDEX = 2`  |\n",
    "| Code Word (hex)     | 92340f0f |                     |\n",
    "\n",
    "These are example values and you cannot assume that these are \"optimal\"!\n",
    "\n",
    "\n",
    "## Design Considerations\n",
    "\n",
    "* It is important to choose settings that will give an optimal channel estimate in the presence of noise and interference. This will generally require long sequences. However, we have to wait until one or two pulse sequences have been received before we can do a channel estimation, and this will from the basis for the location estimate. Faster updates will result in better tracking. For this, it is important to have short sequences! [Activity: determine the maximum duration of a single pulse sequence. Which code parameters determine this?]\n",
    "\n",
    "* Furthermore, we need to plan for a \"guard interval\" of silence between two sequences, long enough for the channel response to return to zero. For a large room and a maximal distance of 5 to 6 meters between the beacon and the microphone, what is that duration (in ms)? This determines the maximal repitition rate that you can hope to achieve.\n",
    "\n",
    "* Another aspect to consider is the dynamic range. The microphone gain will have to be set such that it will not clip even if the transmitter is very close to it, because we want to avoid nonlinear effects. But, in another extreme, over a distance of 5 to 6 meters, the audio signal is already significantly attenuated and may drown in the noise. However, we will have to be able to estimate the channel even over such distances, also in the presence of a nasty interferer close to the microphone. For this, we need long sequences, or to average over several repetitions of the sequence, so that the noise is averaged out and you remain with the channel impulse response.\n",
    "\n",
    "* We found that the best channel estimation results are obtained if the probing signal is wideband, i.e. covers a large bandwidth. Which timer parameter determines the bandwidth of the signal?  \n",
    "\n",
    "* We also looked at the effect of carrier frequencies. Which parameter determines this? Is there a reason to use very high carrier frequencies?\n",
    "\n",
    "* What sample rate should be used? Considerations are the Nyquist condition, but also the computational complexity (at a higher rate you will need to process more samples $N$ and the channel length $L$ is also higher) and the time resolution at which you can detect peaks in the impulse response.\n",
    "\n",
    "* Finally, we have to think of the practical situation where the microphone signal contains beacon signals of more than one user. Consider what happens if you do the deconvolution using a reference signal that does not match the transmitted signal. E.g., in the Matched Filter, we correlate the received signal with our own code sequence, and hopefully the correlation of someone else's code with our own code is small. Thus, the filter will filter out the other signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Fs_TX = 44100\\nNbits = 64\\nTimer0 = 3\\nTimer1 = 8\\nTimer3 = 2\\ncode = 0x92340f0faaaa4321\\n\\nx, _ = refsignal(Nbits, Timer0, Timer1, Timer3, code, Fs_TX)\\nX = # your code here\\n\\nperiod = # your code here\\nt = # your code here\\nf = # your code here\\n\\nfig, ax = plt.subplots(2, 1, figsize=(10, 7))\\n\\nax[0].plot(t, x)\\nax[0].set_title(\"Audio Beacon in the Time Domain\")\\nax[0].set_xlabel(\"Time [s]\")\\nax[0].set_ylabel(\"Magnitude\")\\nax[0].set_xlim([0, 0.015])\\nax[0].set_ylim([0, 2])\\n\\nax[1].plot(f, np.real(X))\\nax[1].set_title(\"Audio Beacon in the Frequency Domain\")\\nax[1].set_xlabel(\"Frequency [kHz]\")\\nax[1].set_ylabel(\"Magnitude\")\\nax[1].set_xlim([0, Fs_TX / 1000])\\nax[1].set_ylim([0, max(np.real(X))])\\n\\nfig.tight_layout() '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Fs_TX = 44100\n",
    "Nbits = 64\n",
    "Timer0 = 3\n",
    "Timer1 = 8\n",
    "Timer3 = 2\n",
    "code = 0x92340f0faaaa4321\n",
    "\n",
    "x, _ = refsignal(Nbits, Timer0, Timer1, Timer3, code, Fs_TX)\n",
    "X = # your code here\n",
    "\n",
    "period = # your code here\n",
    "t = # your code here\n",
    "f = # your code here\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 7))\n",
    "\n",
    "ax[0].plot(t, x)\n",
    "ax[0].set_title(\"Audio Beacon in the Time Domain\")\n",
    "ax[0].set_xlabel(\"Time [s]\")\n",
    "ax[0].set_ylabel(\"Magnitude\")\n",
    "ax[0].set_xlim([0, 0.015])\n",
    "ax[0].set_ylim([0, 2])\n",
    "\n",
    "ax[1].plot(f, np.real(X))\n",
    "ax[1].set_title(\"Audio Beacon in the Frequency Domain\")\n",
    "ax[1].set_xlabel(\"Frequency [kHz]\")\n",
    "ax[1].set_ylabel(\"Magnitude\")\n",
    "ax[1].set_xlim([0, Fs_TX / 1000])\n",
    "ax[1].set_ylim([0, max(np.real(X))])\n",
    "\n",
    "fig.tight_layout() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDOA Estimation\n",
    "\n",
    "In the EPO4 project, we will try to locate a car using an audio beacon. We will use time-difference of arrival (TDOA) measurements made at microphones positioned at known locations. The audio beacon transmits signals which are received by up to 5 microphones. Depending on the distance to each microphone, the signal arrives a little bit earlier or later, and we can convert that into physical distances. For each pair of microphones, we will compute this TDOA, or the physical difference in propogation distance. If we have a large enough number of microphones (4 should work...), then we can calculate the $(x,y)$ location of the transmitter using a Least Squares algorithm. You will do this in the EPO4 project.\n",
    "\n",
    "Before we can do localization, we have to work on this question: Given the impulse responses measured by two microphones, how is the Time Difference of Arrival (TDOA) estimated? That is the topic of this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Outline\n",
    "\n",
    "The audio beacon transmits a continous stream of pulses, using a certain repetition period $T_R$ (specified via the `Timer3` parameter, e.g., 100 ms). If we are not synchronized to the beacon, there is no guarantee that an entire pulse sequence is captured in a period $T_R$: you might have the tail of one sequence, and the head of the next. It is probably easire to capture samples for at least $2T_R$ seconds, i.e., 2 intervals.\n",
    "\n",
    "We aim to apply the deconvolution algorithm to a single full interval in the received data. So the next step is to synchronize to the start of a received pulse in our data. For this Labday, we will do this step by hand, although in EPO4 it will have to be automated:\n",
    "* Locate the start of a pulse\n",
    "* Isolate the entire pulse; try to remove as much of the \"silent period\" as possible.\n",
    "* Since we have two microphones, we have to crop two received signals. Make sure you crop them on precisely the same intervals.\n",
    "\n",
    "To guide the cropping, you will need to consider what is the duration of the beacon pulse, how much longer can it be extended due to the convolution by the audio channel, and how long is the silent period. Use your beacon parameters, consider a maximal propagation distance of 5 m, and convert all times to number of samples.\n",
    "\n",
    "For an automated method, we would look for a silent period of at least some duration $T_I$, followed by a sample that is above some threshold. As threshold, we could take 50% of the maximal amplitude in the data. To be sure, we would include some of the silent interval in the cropped signal.\n",
    "\n",
    "Next, apply your deconvolution algorithm to the cropped received data. We can use two methods:\n",
    "* deconvolve using a reference signal. A suitable reference signal is obtained from a recording at 1 cm.\n",
    "* deconvolve one microphone signal using the signal from the second microphone (preferably, the strongest one).\n",
    "\n",
    "Using the first method, you obtain two channel estimates. Locate the peaks in both estimates: their time difference is the TDOA.\n",
    "For the second method, you have to locate only a single peak. Its time index is the TDOA. But you have to be careful: the TDOA could be negative, and if you used deconvolution algorithm, the channel estimate is periodic and the peak could occur at the far end of the estimate.  \n",
    "\n",
    "Finally, convert the TDOA into a physical distance (knowing the speed of sound).\n",
    "\n",
    "```{figure} TDOA.png\n",
    "---\n",
    "height/width: 150px\n",
    "name: tdoa-figure\n",
    "---\n",
    "TDOA Estimation\n",
    "```\n",
    "\n",
    "The image above shows TDOA estimation: for the impulse response $h_1[n]$ of the first microphone, find the first peak after the silent interval, then go to the second microphone $h_2[n]$ and look for a matching peak in the search window."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}