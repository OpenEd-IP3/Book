{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Locating KITT Using Audio Communication\n",
    "\n",
    "KITT must be located in its field and then directions must be determined to navigate to the final destination. In the previous modules your colleagues are developing scripts to communicate with KITT. They will add functionality to read the audio signals from the microphones located around the field, and you should use these to locate the car. It is recommended to read Modules 1 and 2 to have a better understanding of how everything should work together.\n",
    "\n",
    "For the localization, we will use (real-time) recordings of the beacon signal at the various microphones, deconvolve these using a reference signal recording, and determine the relative time delays from the resulting channel estimates. Depending on the distance to each microphone, the signal transmitted by KITT’s beacon arrives a little bit earlier or later, and you can convert that into physical distances. For each pair of microphones, we can compute this time difference of arrival (TDOA), or the physical difference in propagation distance. If you have measurements from enough microphones, then you can calculate the location of KITT in the field.\n",
    "\n",
    "7 recodings with known locations and a reference recording taken close to the microphone will be provided in this task. This can be used to develop and test your algorithms.\n",
    "\n",
    "At the end of this Module, you will have developed a script to locate KITT within the field with reason- able accuracy, and you will do so using the data recorded by the microphones located along the field. You will also have tested and verified the accuracy and robustness of your solution.\n",
    "\n",
    "\n",
    "## Pre-recorded data\n",
    "\n",
    "These recordings have locations randomly distributed across the field. An example recording with the location are, \n",
    "\n",
    "|   x   |   y   |\n",
    "|-------|-------|\n",
    "|  64   |   40  |\n",
    "|  82   |  399  |\n",
    "|  109  |   76  |\n",
    "|  143  |  296  |\n",
    "|  150  |  185  |\n",
    "|  178  |  439  |\n",
    "|  232  |  275  |\n",
    "\n",
    "*Table 1: Sample Data Table*\n",
    "\n",
    "The x and y axe are defined as follows, where the numbers refer to the microphone index:\n",
    "\n",
    "```{figure} axisdef.png\n",
    "---\n",
    "height/width: 150px\n",
    "name: mic-figure\n",
    "---\n",
    "Microphone Axis definition\n",
    "```\n",
    "You can assume these positions for the microphones. Please note the different height of microphone 5.\n",
    "\n",
    "\n",
    "## Background Knowledge\n",
    "\n",
    "We will study channel estimation: how do we measure the impulse response from a microphone to a loudspeaker? The specific topics you'll learn in this labday are channel estimation in time-domain (matched filter) and frequency domain. In Labday 4, we will test all this on audio signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt           # For plotting purposes\n",
    "import numpy as np                        # For convolution function\n",
    "import scipy\n",
    "from scipy import signal                  # For filter function\n",
    "from scipy.fft import fft, ifft           # For fft and ifft\n",
    "import math                               # For numerical approximation of pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction ##\n",
    "Suppose we transmit a known signal $x[n]$ over a communication\n",
    "channel, and measure the result $y[n]$.  The channel acts as a\n",
    "filter, which we will assume to be linear and time-invariant.\n",
    "Therefore, the measured signal is a convolution of the transmitted\n",
    "signal by the channel impulse response $h[n]$, such that\n",
    "$y[n] = h[n] \\ast x[n]$.  Knowing the transmitted signal $x[n]$, can\n",
    "we recover the impulse response of the communication channel from\n",
    "$y[n]$?  This is essentially an inversion problem.\n",
    "\n",
    "Indeed, if we do this in the frequency domain, we have\n",
    "$\n",
    "H(\\omega) = \\frac{Y(\\omega)}{X(\\omega)}\n",
    "\\,,\n",
    "$\n",
    "\n",
    "and we can recover \\( h[n] \\) from an inverse DTFT. However, there are some complications to do this in the frequency domain. Can we use the DFT instead of the DTFT (which leads to sampling in the frequency domain)?\n",
    "\n",
    "Are there numerical problems with the above division, what if $X(\\omega) = 0$?\n",
    "\n",
    "Will \\( h[n] \\) be causal? What about stability?\n",
    "\n",
    "Alternatively, we can do the deconvolution in the time domain.  This leads to a matrix inversion problem. Also\n",
    "here, there can be numerical problems.  If the matrix is poorly invertible, then additive noise will be enhanced, and\n",
    "the resulting channel impulse response estimate will be poor.\n",
    "\n",
    "We will need channel estimation in the EPO4 project, where each toy\n",
    "car will transmit audio beacon signals, which are recorded by\n",
    "microphones at the corners of the field.  From differences in the\n",
    "estimated channels, we will locate the car.  We also want to be\n",
    "insensitive to interfering signals: if several beacons are\n",
    "transmitting audio signals at the same time, we only want to detect\n",
    "our own transmitting sequence.\n",
    "\n",
    "Estimation of a propagation channel as studied here is fundamental in many applications. In radar it allows to estimate the distance of objects, in geophysics it represents the reflections at earth layers, in medical ultrasound it allows to form an image of a patient.\n",
    "\n",
    "To estimate $h[n]$, three alternative algorithms were described:\n",
    "- Deconvolution in the time domain: Involves matrix inversion. It is computationally complex and\n",
    "requires lots of memory (easily more than what the available PCs can handle).\n",
    "- The matched filter: Avoids the matrix inversion. It is equal to computing the cross-correlation of\n",
    "$y[n]$ with $x[n]$. As cross-correlation is equivalent to a convolution with a reverse signal $x[−n]$, it can be computed efficiently using the FFT. The resulting channel estimate is equal to the true\n",
    "channel convolved with the autocorrelation of the pulse, $x[n] ∗ x[−n]$. Therefore, its performance\n",
    "heavily depends on having the correct (i.e., accurate) “reference” or “training” signal to correlate\n",
    "your measurements with, and the signal should have good autocorrelation properties: $x[n] ∗ x[−n]$\n",
    "should be close to a delta spike. Large sidelobes will lead to confusion.\n",
    "- Deconvolution in the frequency domain: Involves the FFT. It computes the same channel as via\n",
    "deconvolution in the time domain but is much more efficient: convolution in time becomes point-\n",
    "wise multiplication in frequency, hence for deconvolution in the frequency domain, we only need\n",
    "a pointwise division, followed by an IFFT to obtain the time-domain channel impulse response.\n",
    "\n",
    "```{admonition} Note\n",
    "\n",
    "FFT and IFFT lead to periodicities (the result is cyclic, and samples $x[n]$ at negative time reappear\n",
    "at the “large n” part of the signal). Since this method is similar to ch1 (but much more efficient),\n",
    "you can view this method as a matched filter, followed by a correction step that “inverts” the effect\n",
    "of the autocorrelation of the transmit pulse. However, since we should not divide by zero, you will\n",
    "also need to implement a “threshold” to set non-invertible or very small frequency coefficients of\n",
    "$x[n]$ to zero, which otherwise will lead to noise amplification. The performance depends on this\n",
    "threshold, which has to be chosen heuristically.\n",
    "\n",
    "```\n",
    "\n",
    "In each case, a reference signal $x[n]$ is required. We recommend using a recording close to the beacon be-\n",
    "cause then $x[n]$ includes the loudspeaker and microphone responses as well. For the pre-made recordings,\n",
    "a high-quality reference is available.\n",
    "The deconvolution algorithm gives a channel estimate for the beacon path to each microphone. After this,\n",
    "we detect the first incoming path, which, assuming Line of Sight (LOS), corresponds to the propagation\n",
    "delay of the car beacon to each microphone. Unfortunately, we do not know the transmit time, so we only\n",
    "obtain relative propagation delays. If we take the difference of microphone delays, this unknown transmit\n",
    "time is eliminated, so we can obtain time difference of arrival (TDOA) samples for each microphone pair.\n",
    "In the next sections, we will use these to locate the car.\n",
    "\n",
    "## Deconvolution in Frequency Domain ##\n",
    "\n",
    "Deconvolution in time domain may become complicated if the channel length \\( L \\) is large.\n",
    "In that case, $ \\mathbf{X} $ becomes too large to invert. At the same time, the Matched Filter may be imprecise and hard to interpret if the autocorrelation sequence \\( r[n] \\) has large sidelobes. An alternative to the Matched Filter is to do the deconvolution in the frequency domain.\n",
    "\n",
    "Recall that a convolution in the time domain corresponds to a multiplication in the frequency domain. From $ y[n] = h[n] \\ast x[n] $ we can derive $ Y(\\omega) = H(\\omega) X(\\omega) $ and hence we can estimate $ H(\\omega) = \\frac{Y(\\omega)}{X(\\omega)} $.\n",
    "However, this property is valid for the DTFT, whereas in practice we have to use the DFT (or in fact the FFT): we evaluate $\\omega $ for only a fixed set of frequencies $ \\frac{2\\pi}{N} k $, with $ 0 \\le k \\le N-1 $.\n",
    "\n",
    "Since we sample in the frequency domain, we can expect some complications: periodicity and aliasing in the time domain! As we will see there, the complications are minimal if we assume the following:\n",
    "* $ N_y > N_x + L - 1 $, i.e., the training sequence has finite length and the observation is long enough\n",
    "* The sequences \\( x[n] \\), \\( h[n] \\), and \\( y[n] \\) are zero padded to a common length $ N \\ge N_y $.\n",
    "\n",
    "In this case, let \\( X[k] \\) be the DFT of \\( x[n] \\), and similarly for \\( H[k] \\) and \\( Y[k] \\), then\n",
    "\n",
    "$\n",
    "Y[k] = H[k] X[k] \\qquad,  \\mbox{for } 0 \\le k \\le N-1\n",
    "$\n",
    "\n",
    "Given $X[k]$ and $Y[k]$, we can compute\n",
    "\n",
    "$\n",
    "H[k] = \\frac{Y[k]}{X[k]}\\,,\n",
    "\\qquad\n",
    "0 \\le k \\le N-1\n",
    "$\n",
    "\n",
    "and obtain an estimate of the channel in DFT domain.\n",
    "Next, the inverse Fourier transform is applied to the sequence\n",
    "$H[k]$ to obtain the channel impulse reponse $\\mathbf{h}$.  Together these\n",
    "steps implement a deconvolution in frequency domain that should be equal to the channel estimate obtained using the matrix inversion technique.  A major advantage is its computational simplicity: we need 3 FFTs (complexity order $3 N \\log N$) and a pointwise division (complexity order $N$), rather than a matrix\n",
    "inversion of the Toeplitz matrix $\\mathbf{X}$ (complexity order $N_y\\, L^2$).  We also do not need to store large matrices.\n",
    "\n",
    "This method can be done as follows, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "\n",
    "x = np.array([1, -0.5])\n",
    "h = np.array([1, 2, 3, 2, 1])\n",
    "y = np.convolve(x,h)\n",
    "\n",
    "Ny = len(y)      # Length of y\n",
    "Nx = len(x)      # Length of x\n",
    "L = Ny - Nx + 1    #length of channel (reliable?)\n",
    "\n",
    "x = np.append(x, [0]* (L-1))     # Make x same length as y\n",
    "\n",
    "# deconvolution in frequency domain\n",
    "Y = fft(y)             \n",
    "X = fft(x)\n",
    "H = Y/X                 # pointwise division (divide by zero problems?)\n",
    "\n",
    "# Back transformation\n",
    "h = np.real(ifft(H))    # ensure the result is real-valued\n",
    "h = h[0:L]              # optional: truncate to a smaller length L (reliable?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the Matched Filter could be computed in frequency domain. In time\n",
    "domain, the Matched Filter computes $\\hat{h}[n] = y[n] \\ast\n",
    "x[-n]$.  If as before $N_y > N_x + L-1$ and we take care using zero padding that\n",
    "sequences have equal length $N$, then the equivalent of the Matched Filter in\n",
    "frequency domain is\n",
    "$\n",
    "\\hat{H}[k] = Y[k] X^*[k]\n",
    "$\n",
    "Also the Matched Filter could be computed in frequency domain. In time\n",
    "domain, the Matched Filter computes $\\hat{h}[n] = y[n] \\ast\n",
    "x[-n]$.  If as before $N_y > N_x + L-1$ and we take care using zero padding that\n",
    "sequences have equal length $N$, then the equivalent of the Matched Filter in\n",
    "frequency domain is\n",
    "$\n",
    "\\hat{H}[k] = Y[k] X^*[k]\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with deconvolution in frequency-domain ##\n",
    "\n",
    "Since a pointwise division is done in frequency domain, it is\n",
    "immediately clear that the performance will be low for frequencies\n",
    "where $X[k]$ is small.  Thus, this will only work for training\n",
    "sequences that resemble either an impulse or \"white noise\" random\n",
    "sequences, as these have a wide frequency content. A sinusoid is\n",
    "the worst training sequence, since its frequency content is almost\n",
    "zero everywhere. You can't estimate the channel at frequencies where the input signal is zero!\n",
    "\n",
    "In practice, we should invert $X[k]$ only for frequencies where it\n",
    "is sufficiently strong, and set the estimates of the remaining\n",
    "$H[k]$ equal to zero.\n",
    "Suppose we use a threshold $\\epsilon$ and set $\\hat{H}[k] =\n",
    "0$ if $|X[k]| < \\epsilon$. Then the channel estimate $\\hat{H}[k]$\n",
    "which we obtain satisfies\n",
    "\n",
    "\n",
    "$\n",
    "\\hat{H}[k] = H[k] G[k]\\,,\\qquad \\mbox{where }\n",
    "G[k] = \\left\\{\\begin{array}{ll}\n",
    "1, & |X[k]| > \\epsilon \\\\\n",
    "0, & \\mbox{elsewhere} \\end{array}\\right. \\quad \\quad (6)\n",
    "$\n",
    "\n",
    "In time domain, the estimate $\\hat{h}[n] = h[n] \\ast g[n]$ is the\n",
    "convolution of the true channel with this \"selector function\". This\n",
    "will limit the resolution that can be obtained.\n",
    "\n",
    "Another problem with frequency-domain equalization is that\n",
    "there is no guarantee that the computed $\\mathbf{h}$ corresponds to an FIR\n",
    "channel - in general, this will be a vector that has all $N$\n",
    "entries nonzero.\n",
    "\n",
    "Moreover, due to frequency-domain sampling, the channel estimate is one period of a periodic sequence. Therefore, in some cases you may observe that the tail (high-$n$) values of $\\hat{h}[n]$ are in fact values for small negative $n$. This will in particular be visible if you do delay estimation and the delay is negative.\n",
    "\n",
    "## Tasks ##\n",
    "* Implement frequency-domain\n",
    "equalization as a function `ch3`.  As input parameter, include a threshold\n",
    "$\\epsilon$ on the inversion of $X[k]$. As refinement of the previous discussion, we want $\\epsilon$ to be a threshold relative to the peak amplitude in frequency domain: $\\epsilon \\max_k |X[k]|$. Such a relative threshold makes your function insensitive to a scaling of $X[k]$, which could easily occur if you modify $N$.\n",
    "\n",
    "* Test the function using the three test signals.\n",
    "\n",
    "```{hint}\n",
    "The indices of\n",
    "the entries of a vector smaller than the relative threshold are found like this:\n",
    "`ii = np.absolute(X) < epsi*max(np.absolute(X))`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch3(x,y,Lhat,epsi):\n",
    "    # your code here            # Length of x\n",
    "    # your code here              # Length of y\n",
    "    # your code here            # Length of h\n",
    "\n",
    "    # Force x to be the same length as y\n",
    "   # your code here\n",
    "\n",
    "    # Deconvolution in frequency domain\n",
    "    # your code here\n",
    "\n",
    "    # Threshold to avoid blow ups of noise during inversion\n",
    "    # your code here\n",
    "\n",
    "    #h = # your code here    # ensure the result is real\n",
    "    #h = # your code here    # optional: truncate to length Lhat (L is not reliable?)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your ch3 function here:\n",
    "# Channel\n",
    "h = np.array([1, 2, 3, 2, 1])\n",
    "Lhat = 5      # estimate of channel length L, but could be different\n",
    "\n",
    "# Input length\n",
    "Nx = 20\n",
    "\n",
    "# Input: x1, x2, x3\n",
    "# your code here\n",
    "\n",
    "## output: y1, y2, y3\n",
    "# your code here\n",
    "\n",
    "\n",
    "# Channel estimation via deconvolution: h1, h2, h3\n",
    "# suitable epsi: try values between 0.001 and 0.05\n",
    "# your code here\n",
    "\n",
    "# Print result, should give true channel (which is [1,2,3,2,1])\n",
    "#print(h1)\n",
    "#print(h2)\n",
    "#print(h3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a training sequence $x[n]$ whose frequency\n",
    "domain $X[k]$ is bandlimited, e.g., only contains frequencies smaller\n",
    "than $F_c = 1$ kHz whereas the sample frequency is $F_s = 20$ kHz.\n",
    "\n",
    "```{figure} XFplot.png\n",
    "---\n",
    "height/width: 150px\n",
    "name: xf-figure\n",
    "---\n",
    "Frequency domain plot\n",
    "```\n",
    "\n",
    "The effect of the threshold technique on $\\hat{h}[n]$ is given by\n",
    "$(6)$.  What is $G[k]$ in this case?  And $g[n]$?\n",
    "Make plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 20     # unit: kHz\n",
    "Nsamples = 100\n",
    "#F = #your code here # freq axis 0..10 kHz\n",
    "\n",
    "#G = #your code here    # Let G = 1 only for 0..1 kHz\n",
    "#g = #your code here\n",
    "\n",
    "''' frequency domain\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(#your code here)\n",
    "plt.xlabel('F [kHz]')\n",
    "plt.ylabel('Amplitude') '''\n",
    "\n",
    "# time domain, plot the normalized amplitude (max=1)\n",
    "'''t = #your code here\n",
    "plt.subplot(122)\n",
    "plt.plot(#your code here);\n",
    "plt.xlabel('t [ms]')\n",
    "plt.ylabel('Amplitude [normalized]')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "Channel estimation in frequency domain is generally efficient and accurate.\n",
    "A threshold is needed to avoid inverting small values in the spectrum of the input signal: we cannot estimate the channel at frequencies which are not in the input signal. The \"missing frequencies\" determine the accuracy.\n",
    "\n",
    "In practice, we have training sequences that are bandlimited, and we can estimate channels only in a frequency band. It should not matter too much which band is selected (i.e. the carrier frequency is not important), although the carrier frequency will show up in the channel estimate as a modulation. The bandwidth of the input signal determines the resolution of the channel estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "root = tk.Tk()\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opened",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
